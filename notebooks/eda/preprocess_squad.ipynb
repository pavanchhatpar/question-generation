{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_gan.data import Squad2\n",
    "from text_gan.data.qgen_data import CONFIG\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_tokenize(str_tensor):\n",
    "    str_npy = str_tensor.numpy()\n",
    "    tokens = nlp(str_npy.decode('utf-8'))\n",
    "    return [[\n",
    "        token.orth_ for token in tokens\n",
    "        if not token.is_punct | token.is_space]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tfds.load(\"squad2\", data_dir=\"/tf/data/tf_data\", split='validation')\n",
    "context = data.map(lambda x: tf.py_function(py_tokenize, [x['context']], tf.string), num_parallel_calls=-1)\n",
    "questions = data.map(lambda x: tf.py_function(py_tokenize, [x['question']], tf.string), num_parallel_calls=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'answers': {'answer_start': array([28, 28, 96, 28], dtype=int32),\n  'text': array([b'Lake Constance', b'Lake Constance', b'West by the Alter Rhein',\n         b'Lake Constance'], dtype=object)},\n 'context': b'The mouth of the Rhine into Lake Constance forms an inland delta. The delta is delimited in the West by the Alter Rhein (\"Old Rhine\") and in the East by a modern canalized section. Most of the delta is a nature reserve and bird sanctuary. It includes the Austrian towns of Gai\\xc3\\x9fau, H\\xc3\\xb6chst and Fu\\xc3\\x9fach. The natural Rhine originally branched into at least two arms and formed small islands by precipitating sediments. In the local Alemannic dialect, the singular is pronounced \"Isel\" and this is also the local pronunciation of Esel (\"Donkey\"). Many local fields have an official name containing this element.',\n 'id': b'572fe4a304bcaa1900d76e55',\n 'question': b'The inland delta at the mouth of the Rhine is with what Lake?',\n 'title': b'Rhine'}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "iter = data.as_numpy_iterator()\n",
    "next(iter)\n",
    "next(iter)\n",
    "next(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-12a4c155a767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df = pd.DataFrame({\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'clen'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'qlen'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3642\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2470\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'clen': list(map(lambda x: len(x), context.as_numpy_iterator())),\n",
    "    'qlen': list(map(lambda x: len(x), questions.as_numpy_iterator()))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.5,.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnumpy = list(context.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[array([b'Among', b'the', b'most', b'important', b'classes', b'of',\n        b'organic', b'compounds', b'that', b'contain', b'oxygen', b'are',\n        b'where', b'R', b'is', b'an', b'organic', b'group', b'alcohols',\n        b'R', b'OH', b'ethers', b'R', b'O', b'R', b'ketones', b'R', b'CO',\n        b'R', b'aldehydes', b'R', b'CO', b'H', b'carboxylic', b'acids',\n        b'R', b'COOH', b'esters', b'R', b'COO', b'R', b'acid',\n        b'anhydrides', b'R', b'CO', b'O', b'CO', b'R', b'and', b'amides',\n        b'R', b'C(O)-NR', b'2', b'There', b'are', b'many', b'important',\n        b'organic', b'solvents', b'that', b'contain', b'oxygen',\n        b'including', b'acetone', b'methanol', b'ethanol', b'isopropanol',\n        b'furan', b'THF', b'diethyl', b'ether', b'dioxane', b'ethyl',\n        b'acetate', b'DMF', b'DMSO', b'acetic', b'acid', b'and', b'formic',\n        b'acid', b'Acetone', b'CH', b'3', b'2CO', b'and', b'phenol', b'C',\n        b'6H', b'5OH', b'are', b'used', b'as', b'feeder', b'materials',\n        b'in', b'the', b'synthesis', b'of', b'many', b'different',\n        b'substances', b'Other', b'important', b'organic', b'compounds',\n        b'that', b'contain', b'oxygen', b'are', b'glycerol',\n        b'formaldehyde', b'glutaraldehyde', b'citric', b'acid', b'acetic',\n        b'anhydride', b'and', b'acetamide', b'Epoxides', b'are', b'ethers',\n        b'in', b'which', b'the', b'oxygen', b'atom', b'is', b'part', b'of',\n        b'a', b'ring', b'of', b'three', b'atoms'], dtype=object),\n array([b'The', b'addition', b'of', b'new', b'rock', b'units', b'both',\n        b'depositionally', b'and', b'intrusively', b'often', b'occurs',\n        b'during', b'deformation', b'Faulting', b'and', b'other',\n        b'deformational', b'processes', b'result', b'in', b'the',\n        b'creation', b'of', b'topographic', b'gradients', b'causing',\n        b'material', b'on', b'the', b'rock', b'unit', b'that', b'is',\n        b'increasing', b'in', b'elevation', b'to', b'be', b'eroded', b'by',\n        b'hillslopes', b'and', b'channels', b'These', b'sediments', b'are',\n        b'deposited', b'on', b'the', b'rock', b'unit', b'that', b'is',\n        b'going', b'down', b'Continual', b'motion', b'along', b'the',\n        b'fault', b'maintains', b'the', b'topographic', b'gradient', b'in',\n        b'spite', b'of', b'the', b'movement', b'of', b'sediment', b'and',\n        b'continues', b'to', b'create', b'accommodation', b'space', b'for',\n        b'the', b'material', b'to', b'deposit', b'Deformational',\n        b'events', b'are', b'often', b'also', b'associated', b'with',\n        b'volcanism', b'and', b'igneous', b'activity', b'Volcanic',\n        b'ashes', b'and', b'lavas', b'accumulate', b'on', b'the',\n        b'surface', b'and', b'igneous', b'intrusions', b'enter', b'from',\n        b'below', b'Dikes', b'long', b'planar', b'igneous', b'intrusions',\n        b'enter', b'along', b'cracks', b'and', b'therefore', b'often',\n        b'form', b'in', b'large', b'numbers', b'in', b'areas', b'that',\n        b'are', b'being', b'actively', b'deformed', b'This', b'can',\n        b'result', b'in', b'the', b'emplacement', b'of', b'dike',\n        b'swarms', b'such', b'as', b'those', b'that', b'are',\n        b'observable', b'across', b'the', b'Canadian', b'shield', b'or',\n        b'rings', b'of', b'dikes', b'around', b'the', b'lava', b'tube',\n        b'of', b'a', b'volcano'], dtype=object),\n array([b'The', b'mouth', b'of', b'the', b'Rhine', b'into', b'Lake',\n        b'Constance', b'forms', b'an', b'inland', b'delta', b'The',\n        b'delta', b'is', b'delimited', b'in', b'the', b'West', b'by',\n        b'the', b'Alter', b'Rhein', b'Old', b'Rhine', b'and', b'in',\n        b'the', b'East', b'by', b'a', b'modern', b'canalized', b'section',\n        b'Most', b'of', b'the', b'delta', b'is', b'a', b'nature',\n        b'reserve', b'and', b'bird', b'sanctuary', b'It', b'includes',\n        b'the', b'Austrian', b'towns', b'of', b'Gai\\xc3\\x9fau',\n        b'H\\xc3\\xb6chst', b'and', b'Fu\\xc3\\x9fach', b'The', b'natural',\n        b'Rhine', b'originally', b'branched', b'into', b'at', b'least',\n        b'two', b'arms', b'and', b'formed', b'small', b'islands', b'by',\n        b'precipitating', b'sediments', b'In', b'the', b'local',\n        b'Alemannic', b'dialect', b'the', b'singular', b'is',\n        b'pronounced', b'Isel', b'and', b'this', b'is', b'also', b'the',\n        b'local', b'pronunciation', b'of', b'Esel', b'Donkey', b'Many',\n        b'local', b'fields', b'have', b'an', b'official', b'name',\n        b'containing', b'this', b'element'], dtype=object),\n array([b'A', b'computational', b'problem', b'can', b'be', b'viewed',\n        b'as', b'an', b'infinite', b'collection', b'of', b'instances',\n        b'together', b'with', b'a', b'solution', b'for', b'every',\n        b'instance', b'The', b'input', b'string', b'for', b'a',\n        b'computational', b'problem', b'is', b'referred', b'to', b'as',\n        b'a', b'problem', b'instance', b'and', b'should', b'not', b'be',\n        b'confused', b'with', b'the', b'problem', b'itself', b'In',\n        b'computational', b'complexity', b'theory', b'a', b'problem',\n        b'refers', b'to', b'the', b'abstract', b'question', b'to', b'be',\n        b'solved', b'In', b'contrast', b'an', b'instance', b'of', b'this',\n        b'problem', b'is', b'a', b'rather', b'concrete', b'utterance',\n        b'which', b'can', b'serve', b'as', b'the', b'input', b'for', b'a',\n        b'decision', b'problem', b'For', b'example', b'consider', b'the',\n        b'problem', b'of', b'primality', b'testing', b'The', b'instance',\n        b'is', b'a', b'number', b'e.g.', b'15', b'and', b'the',\n        b'solution', b'is', b'yes', b'if', b'the', b'number', b'is',\n        b'prime', b'and', b'no', b'otherwise', b'in', b'this', b'case',\n        b'no', b'Stated', b'another', b'way', b'the', b'instance', b'is',\n        b'a', b'particular', b'input', b'to', b'the', b'problem', b'and',\n        b'the', b'solution', b'is', b'the', b'output', b'corresponding',\n        b'to', b'the', b'given', b'input'], dtype=object),\n array([b'Paul', b'Revere', b'was', b'descended', b'from', b'Huguenot',\n        b'refugees', b'as', b'was', b'Henry', b'Laurens', b'who',\n        b'signed', b'the', b'Articles', b'of', b'Confederation', b'for',\n        b'South', b'Carolina', b'Jack', b'Jouett', b'who', b'made', b'the',\n        b'ride', b'from', b'Cuckoo', b'Tavern', b'to', b'warn', b'Thomas',\n        b'Jefferson', b'and', b'others', b'that', b'Tarleton', b'and',\n        b'his', b'men', b'were', b'on', b'their', b'way', b'to', b'arrest',\n        b'him', b'for', b'crimes', b'against', b'the', b'king', b'Francis',\n        b'Marion', b'and', b'a', b'number', b'of', b'other', b'leaders',\n        b'of', b'the', b'American', b'Revolution', b'and', b'later',\n        b'statesmen', b'The', b'last', b'active', b'Huguenot',\n        b'congregation', b'in', b'North', b'America', b'worships', b'in',\n        b'Charleston', b'South', b'Carolina', b'at', b'a', b'church',\n        b'that', b'dates', b'to', b'1844', b'The', b'Huguenot', b'Society',\n        b'of', b'America', b'maintains', b'Manakin', b'Episcopal',\n        b'Church', b'in', b'Virginia', b'as', b'an', b'historic',\n        b'shrine', b'with', b'occasional', b'services', b'The', b'Society',\n        b'has', b'chapters', b'in', b'numerous', b'states', b'with',\n        b'the', b'one', b'in', b'Texas', b'being', b'the', b'largest'],\n       dtype=object),\n array([b'A', b'problem', b'is', b'regarded', b'as', b'inherently',\n        b'difficult', b'if', b'its', b'solution', b'requires',\n        b'significant', b'resources', b'whatever', b'the', b'algorithm',\n        b'used', b'The', b'theory', b'formalizes', b'this', b'intuition',\n        b'by', b'introducing', b'mathematical', b'models', b'of',\n        b'computation', b'to', b'study', b'these', b'problems', b'and',\n        b'quantifying', b'the', b'amount', b'of', b'resources', b'needed',\n        b'to', b'solve', b'them', b'such', b'as', b'time', b'and',\n        b'storage', b'Other', b'complexity', b'measures', b'are', b'also',\n        b'used', b'such', b'as', b'the', b'amount', b'of',\n        b'communication', b'used', b'in', b'communication', b'complexity',\n        b'the', b'number', b'of', b'gates', b'in', b'a', b'circuit',\n        b'used', b'in', b'circuit', b'complexity', b'and', b'the',\n        b'number', b'of', b'processors', b'used', b'in', b'parallel',\n        b'computing', b'One', b'of', b'the', b'roles', b'of',\n        b'computational', b'complexity', b'theory', b'is', b'to',\n        b'determine', b'the', b'practical', b'limits', b'on', b'what',\n        b'computers', b'can', b'and', b'can', b'not', b'do'], dtype=object),\n array([b'In', b'front', b'of', b'the', b'Presiding', b'Officers', b'desk',\n        b'is', b'the', b'parliamentary', b'mace', b'which', b'is', b'made',\n        b'from', b'silver', b'and', b'inlaid', b'with', b'gold', b'panned',\n        b'from', b'Scottish', b'rivers', b'and', b'inscribed', b'with',\n        b'the', b'words', b'Wisdom', b'Compassion', b'Justice', b'and',\n        b'Integrity', b'The', b'words', b'There', b'shall', b'be', b'a',\n        b'Scottish', b'Parliament', b'which', b'are', b'the', b'first',\n        b'words', b'of', b'the', b'Scotland', b'Act', b'are', b'inscribed',\n        b'around', b'the', b'head', b'of', b'the', b'mace', b'which',\n        b'has', b'a', b'formal', b'ceremonial', b'role', b'in', b'the',\n        b'meetings', b'of', b'Parliament', b'reinforcing', b'the',\n        b'authority', b'of', b'the', b'Parliament', b'in', b'its',\n        b'ability', b'to', b'make', b'laws', b'Presented', b'to', b'the',\n        b'Scottish', b'Parliament', b'by', b'the', b'Queen', b'upon',\n        b'its', b'official', b'opening', b'in', b'July', b'1999', b'the',\n        b'mace', b'is', b'displayed', b'in', b'a', b'glass', b'case',\n        b'suspended', b'from', b'the', b'lid', b'At', b'the', b'beginning',\n        b'of', b'each', b'sitting', b'in', b'the', b'chamber', b'the',\n        b'lid', b'of', b'the', b'case', b'is', b'rotated', b'so', b'that',\n        b'the', b'mace', b'is', b'above', b'the', b'glass', b'to',\n        b'symbolise', b'that', b'a', b'full', b'meeting', b'of', b'the',\n        b'Parliament', b'is', b'taking', b'place'], dtype=object),\n array([b'The', b'most', b'commonly', b'used', b'reduction', b'is', b'a',\n        b'polynomial', b'time', b'reduction', b'This', b'means', b'that',\n        b'the', b'reduction', b'process', b'takes', b'polynomial', b'time',\n        b'For', b'example', b'the', b'problem', b'of', b'squaring', b'an',\n        b'integer', b'can', b'be', b'reduced', b'to', b'the', b'problem',\n        b'of', b'multiplying', b'two', b'integers', b'This', b'means',\n        b'an', b'algorithm', b'for', b'multiplying', b'two', b'integers',\n        b'can', b'be', b'used', b'to', b'square', b'an', b'integer',\n        b'Indeed', b'this', b'can', b'be', b'done', b'by', b'giving',\n        b'the', b'same', b'input', b'to', b'both', b'inputs', b'of',\n        b'the', b'multiplication', b'algorithm', b'Thus', b'we', b'see',\n        b'that', b'squaring', b'is', b'not', b'more', b'difficult',\n        b'than', b'multiplication', b'since', b'squaring', b'can', b'be',\n        b'reduced', b'to', b'multiplication'], dtype=object),\n array([b'The', b'development', b'of', b'plate', b'tectonics', b'provided',\n        b'a', b'physical', b'basis', b'for', b'many', b'observations',\n        b'of', b'the', b'solid', b'Earth', b'Long', b'linear', b'regions',\n        b'of', b'geologic', b'features', b'could', b'be', b'explained',\n        b'as', b'plate', b'boundaries', b'Mid', b'ocean', b'ridges',\n        b'high', b'regions', b'on', b'the', b'seafloor', b'where',\n        b'hydrothermal', b'vents', b'and', b'volcanoes', b'exist', b'were',\n        b'explained', b'as', b'divergent', b'boundaries', b'where', b'two',\n        b'plates', b'move', b'apart', b'Arcs', b'of', b'volcanoes', b'and',\n        b'earthquakes', b'were', b'explained', b'as', b'convergent',\n        b'boundaries', b'where', b'one', b'plate', b'subducts', b'under',\n        b'another', b'Transform', b'boundaries', b'such', b'as', b'the',\n        b'San', b'Andreas', b'fault', b'system', b'resulted', b'in',\n        b'widespread', b'powerful', b'earthquakes', b'Plate', b'tectonics',\n        b'also', b'provided', b'a', b'mechanism', b'for', b'Alfred',\n        b'Wegener', b\"'s\", b'theory', b'of', b'continental', b'drift',\n        b'in', b'which', b'the', b'continents', b'move', b'across', b'the',\n        b'surface', b'of', b'the', b'Earth', b'over', b'geologic', b'time',\n        b'They', b'also', b'provided', b'a', b'driving', b'force', b'for',\n        b'crustal', b'deformation', b'and', b'a', b'new', b'setting',\n        b'for', b'the', b'observations', b'of', b'structural', b'geology',\n        b'The', b'power', b'of', b'the', b'theory', b'of', b'plate',\n        b'tectonics', b'lies', b'in', b'its', b'ability', b'to',\n        b'combine', b'all', b'of', b'these', b'observations', b'into',\n        b'a', b'single', b'theory', b'of', b'how', b'the', b'lithosphere',\n        b'moves', b'over', b'the', b'convecting', b'mantle'], dtype=object),\n array([b'On', b'May', b'3', b'1901', b'downtown', b'Jacksonville', b'was',\n        b'ravaged', b'by', b'a', b'fire', b'that', b'started', b'as', b'a',\n        b'kitchen', b'fire', b'Spanish', b'moss', b'at', b'a', b'nearby',\n        b'mattress', b'factory', b'was', b'quickly', b'engulfed', b'in',\n        b'flames', b'and', b'enabling', b'the', b'fire', b'to', b'spread',\n        b'rapidly', b'In', b'just', b'eight', b'hours', b'it', b'swept',\n        b'through', b'146', b'city', b'blocks', b'destroyed', b'over',\n        b'2,000', b'buildings', b'left', b'about', b'10,000', b'homeless',\n        b'and', b'killed', b'7', b'residents', b'The', b'Confederate',\n        b'Monument', b'in', b'Hemming', b'Park', b'was', b'one', b'of',\n        b'the', b'only', b'landmarks', b'to', b'survive', b'the', b'fire',\n        b'Governor', b'Jennings', b'declare', b'martial', b'law', b'and',\n        b'sent', b'the', b'state', b'militia', b'to', b'maintain',\n        b'order', b'On', b'May', b'17', b'municipal', b'authority',\n        b'resumed', b'in', b'Jacksonville', b'It', b'is', b'said', b'the',\n        b'glow', b'from', b'the', b'flames', b'could', b'be', b'seen',\n        b'in', b'Savannah', b'Georgia', b'and', b'the', b'smoke',\n        b'plumes', b'seen', b'in', b'Raleigh', b'North', b'Carolina',\n        b'Known', b'as', b'the', b'Great', b'Fire', b'of', b'1901', b'it',\n        b'was', b'one', b'of', b'the', b'worst', b'disasters', b'in',\n        b'Florida', b'history', b'and', b'the', b'largest', b'urban',\n        b'fire', b'in', b'the', b'southeastern', b'United', b'States',\n        b'Architect', b'Henry', b'John', b'Klutho', b'was', b'a',\n        b'primary', b'figure', b'in', b'the', b'reconstruction', b'of',\n        b'the', b'city', b'The', b'first', b'multi', b'story',\n        b'structure', b'built', b'by', b'Klutho', b'was', b'the', b'Dyal',\n        b'Upchurch', b'Building', b'in', b'1902', b'The', b'St.', b'James',\n        b'Building', b'built', b'on', b'the', b'previous', b'site', b'of',\n        b'the', b'St.', b'James', b'Hotel', b'that', b'burned', b'down',\n        b'was', b'built', b'in', b'1912', b'as', b'Klutho', b\"'s\",\n        b'crowning', b'achievement'], dtype=object)]"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "cnumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnumpy = list(questions.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvocab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tqdm(cnumpy):\n",
    "    for i, ci in enumerate(c):\n",
    "        if i >= 250:\n",
    "            break\n",
    "        cvocab[ci] = cvocab.get(ci, 0) + 1\n",
    "len(cvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'token':list(cvocab.keys()), 'count':list(cvocab.values())})\n",
    "df = df.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  token    count\n0   the  3153117\n1     ,  2447504\n2    of  1828706\n3     .  1730663\n4   and  1477507",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>3153117</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>2447504</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>of</td>\n      <td>1828706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>.</td>\n      <td>1730663</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>1477507</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "df.loc[:, 'token'] = df.token.map(lambda x: x.decode('utf-8'))\n",
    "df.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'1669209 word embeddings found'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "glove_embs_path = \"/tf/data/squad/glove.840B.300d/glove.840B.300d.txt\"\n",
    "word2embs = {}\n",
    "with open(glove_embs_path, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while len(line) != 0:\n",
    "        word_vec = line.split(' ')\n",
    "        word = word_vec[0]\n",
    "        vec = np.array(word_vec[1:], dtype=np.float32)\n",
    "        word2embs[word] = vec\n",
    "        line = f.readline()\n",
    "f\"{len(word2embs)} word embeddings found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100355, 2)"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "df[df['count'] > 10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 100355/100355 [00:00<00:00, 1070976.27it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'23669 tokens not in glove'"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "oov = 0\n",
    "oov_tokens = []\n",
    "for token in tqdm(df[df['count'] > 10].token):\n",
    "    if token not in word2embs:\n",
    "        oov += 1\n",
    "        oov_tokens.append(token)\n",
    "f\"{oov} tokens not in glove\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 130319/130319 [00:00<00:00, 163714.64it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50899"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "qvocab={}\n",
    "for c in tqdm(qnumpy):\n",
    "    for i, ci in enumerate(c):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        qvocab[ci] = qvocab.get(ci, 0) + 1\n",
    "len(qvocab)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              token   count\n0                 ?  117900\n1               the   88126\n2              What   59304\n3                of   48790\n4                in   32308\n...             ...     ...\n50894     prestiges       1\n50895   istitutions       1\n50896  unattractive       1\n50897       immense       1\n50898          Bani       1\n\n[50899 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>?</td>\n      <td>117900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the</td>\n      <td>88126</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What</td>\n      <td>59304</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>of</td>\n      <td>48790</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in</td>\n      <td>32308</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50894</th>\n      <td>prestiges</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50895</th>\n      <td>istitutions</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50896</th>\n      <td>unattractive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50897</th>\n      <td>immense</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50898</th>\n      <td>Bani</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>50899 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "qdf = pd.DataFrame({'token':list(qvocab.keys()), 'count':list(qvocab.values())})\n",
    "qdf = qdf.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "qdf.loc[:, 'token'] = qdf.token.map(lambda x: x.decode('utf-8'))\n",
    "qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5431, 2)"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "qdf[qdf['count'] > 20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 5000/5000 [00:00<00:00, 1019866.75it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'78 tokens not in glove'"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "oov = 0\n",
    "oov_tokens = []\n",
    "for token in tqdm(qdf.iloc[:5000].token):\n",
    "    if token not in word2embs:\n",
    "        oov += 1\n",
    "        oov_tokens.append(token)\n",
    "f\"{oov} tokens not in glove\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}