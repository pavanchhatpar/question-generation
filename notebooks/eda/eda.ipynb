{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_gan import cfg, Vocab\n",
    "from text_gan.features import GloVeReader, NERTagger, PosTagger\n",
    "from text_gan.utils import MapReduce\n",
    "\n",
    "import en_core_web_sm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_reader = GloVeReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loading vectors: 1669210it [02:19, 11937.12it/s]\n"
    }
   ],
   "source": [
    "pretrained_vectors = embedding_reader.read(cfg.EMBS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(\n",
    "    embedding_reader.START,\n",
    "    embedding_reader.END,\n",
    "    embedding_reader.PAD,\n",
    "    embedding_reader.UNK,\n",
    "    cfg.CSEQ_LEN,\n",
    "    cfg.QSEQ_LEN,\n",
    "    pretrained_vectors\n",
    ")\n",
    "ner = NERTagger(cfg.NER_TAGS_FILE, cfg.CSEQ_LEN)\n",
    "pos = PosTagger(cfg.POS_TAGS_FILE, cfg.CSEQ_LEN)\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfds.load(\"squad\", data_dir=\"/tf/data/tf_data\", split='train').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(x):\n",
    "    context, question, ans = list(nlp.pipe([\n",
    "        x['context'].decode('utf-8'),\n",
    "        x['question'].decode('utf-8'),\n",
    "        x['answers']['text'][0].decode('utf-8')\n",
    "    ]))\n",
    "    del x\n",
    "    return (context, question, ans)\n",
    "\n",
    "def substrSearch(ans, context):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    s = -1\n",
    "    while i < len(context) and j < len(ans):\n",
    "        if context[i].text == ans[j].text:\n",
    "            s = i\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            j = 0\n",
    "            s = -1\n",
    "    return s, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = MapReduce()\n",
    "train_iter = train.as_numpy_iterator()\n",
    "train_tokenized = mr.process(tokenize_example, train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10, 10, 10)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_context = []\n",
    "train_question = []\n",
    "train_ans = []\n",
    "for context, ques, ans in train_tokenized:\n",
    "    ans_start, l = substrSearch(ans, context)\n",
    "    if len(ques) >= 20 or ans_start == -1 or ans_start + l >= 250:\n",
    "        continue\n",
    "    train_context.append(context)\n",
    "    train_question.append(ques)\n",
    "    train_ans.append((ans_start, l))\n",
    "len(train_context), len(train_question), len(train_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cembs.fit(train_context)\n",
    "# qembs.fit(train_question)\n",
    "train_cidx = vocab.transform(train_context, \"source\")\n",
    "train_ner = ner.transform(train_context)\n",
    "train_pos = ner.transform(train_context)\n",
    "train_qidx = vocab.transform(train_question, \"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([    2,    26,  1313,    11,     6,   543,  2564,    15,     6,\n         361,     9,     1,    14,     6,   678,    19,   126, 14742,\n          18, 27592,  2770,    15,     6,   413,    17,  1425,  6387,\n       34515,     5,   152, 15365,   586,     6,  1264,     4, 25729,\n       33624, 27592,  4875, 13110,     5,   152,   174,  5182,     6,\n        3203, 27074,    15,   130,  5377,    27, 14230, 20683, 33624,\n           5,    94,    89,  1414,   165,     6,  3203,  9910,   269,\n         138,    11,   101,   837,     4,    32,    11,  1326,  3512,\n           4,     6,  1266,  1971, 27074,   129,  3509, 34515,     4,\n         170,    32,  8807, 34515,    29,    43,  5103,    18,    23,\n         231,  6387,     7,  9084,  2843,    17,    36, 11523, 34515,\n           5,     3,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_cidx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([   2,  194,   14,   55,  129,   19,   73, 1593,   43, 9910,    8,\n       1058, 5377,   11,  823,  951,   29,  478,   41,    3])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_qidx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "41"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "vocab._source['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseq = cfg.CSEQ_LEN\n",
    "qseq = cfg.QSEQ_LEN\n",
    "\n",
    "def gen():\n",
    "    for cidx, ner, pos, qidx, ans in zip(\n",
    "            train_cidx, train_ner, train_pos,\n",
    "            train_qidx, train_ans):\n",
    "        yield (cidx, ans, qidx, ner, pos)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    gen,\n",
    "    (tf.int32, tf.int32, tf.int32, tf.uint8, tf.uint8),\n",
    "    (\n",
    "        tf.TensorShape([cseq]), tf.TensorShape([2]),\n",
    "        tf.TensorShape([qseq]), tf.TensorShape([cseq]), tf.TensorShape([cseq]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total 10\n"
    }
   ],
   "source": [
    "i = 0\n",
    "for cidx, ans, qidx, ner, pos in train_dataset:\n",
    "    i += 1\n",
    "print(\"Total\", i)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}